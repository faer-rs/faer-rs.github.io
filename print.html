<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title></title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title"></h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/sarah-quinones/faer-rs" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="introduction"><a class="header" href="#introduction">introduction</a></h1>
<p><em><code>faer</code></em> is a linear algebra library developed in the rust programming language.
it exposes a high level abstraction over a lower level api, similar to the one offered by blas/lapack libraries, modified to better match the capabilities of modern computers, and allows tweaking the inner parameters of the various algorithms.</p>
<h1 id="community"><a class="header" href="#community">community</a></h1>
<p>most of the discussion around the library happens on the <a href="https://discord.gg/Ak5jDsAFVZ">discord</a> server. users who have questions about using the library, performance issues, bug reports, etc, as well as people looking to contribute, are welcome to join the server!</p>
<p>bug reports and pull requests can also be posted on the <a href="https://www.github.com/sarah-ek/faer-rs">github</a> repository.</p>
<h1 id="available-features"><a class="header" href="#available-features">available features</a></h1>
<ul>
<li>matrix creation and basic operation (addition, subtraction, multiplication, etc.),</li>
<li>high performance matrix multiplication,</li>
<li>triangular solvers,</li>
<li>cholesky decomposition, llt, ldlt, and bunch-kaufman lblt,</li>
<li>lu decomposition, with partial or full pivoting,</li>
<li>qr decomposition, with or without column pivoting.</li>
<li>svd decomposition.</li>
<li>eigenvalue decomposition for hermitian and non hermitian (real or complex) matrices.</li>
<li>sparse algorithms.</li>
</ul>
<h1 id="future-plans"><a class="header" href="#future-plans">future plans</a></h1>
<ul>
<li>n-dimensional tensor structures and operations.</li>
<li>gpu acceleration.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><p>to use faer in your project, you can add the required dependency to your <code>cargo.toml</code> file.</p>
<pre><code class="language-toml">[dependencies]
faer = "0.19"
</code></pre>
<p>for day-to-day development, we recommend enabling optimizations for <em><code>faer</code></em>, since the layers of generics can add considerable overhead in unoptimized builds.
this can be done by adding the following to <code>Cargo.toml</code></p>
<pre><code class="language-toml">[profile.dev.package.faer]
opt-level = 3
</code></pre>
<p>we recommend new users to skim the user guide provided in the sidebar, and defer to the docs for more detailed information.</p>
<div style="break-before: page; page-break-before: always;"></div><p>the benchmarks were run on an <code>11th gen intel(r) core(tm) i5-11400 @ 2.60ghz</code> with 1 thread (hyperthreading off).</p>
<p>all computations are done on column major matrices.</p>
<p>the plots are normalized so that the <em><code>faer</code></em> line is set to <code>1.0</code>.</p>
<p>higher is better on all the plots.</p>
<p>last updated: 2024-05-25</p>
<h2 id="f32"><a class="header" href="#f32">f32</a></h2>
<p><img src="./plots/st_cholesky_f32_plot.png" alt="cholesky" /></p>
<hr />
<p><img src="./plots/st_qr_f32_plot.png" alt="qr" /></p>
<hr />
<p><img src="./plots/st_piv_qr_f32_plot.png" alt="qr with column pivoting" /></p>
<hr />
<p><img src="./plots/st_lu_f32_plot.png" alt="lu with partial pivoting" /></p>
<hr />
<p><img src="./plots/st_piv_lu_f32_plot.png" alt="lu with full pivoting" /></p>
<hr />
<p><img src="./plots/st_svd_f32_plot.png" alt="singular value decomposition" /></p>
<hr />
<p><img src="./plots/st_thin_svd_f32_plot.png" alt="thin singular value decomposition" /></p>
<hr />
<p><img src="./plots/st_eigh_f32_plot.png" alt="self adjoint eigenvalue decomposition" /></p>
<hr />
<p><img src="./plots/st_eig_f32_plot.png" alt="eigenvalue decomposition" /></p>
<hr />
<h2 id="f64"><a class="header" href="#f64">f64</a></h2>
<p><img src="./plots/st_cholesky_f64_plot.png" alt="cholesky" /></p>
<hr />
<p><img src="./plots/st_qr_f64_plot.png" alt="qr" /></p>
<hr />
<p><img src="./plots/st_piv_qr_f64_plot.png" alt="qr with column pivoting" /></p>
<hr />
<p><img src="./plots/st_lu_f64_plot.png" alt="lu with partial pivoting" /></p>
<hr />
<p><img src="./plots/st_piv_lu_f64_plot.png" alt="lu with full pivoting" /></p>
<hr />
<p><img src="./plots/st_svd_f64_plot.png" alt="singular value decomposition" /></p>
<hr />
<p><img src="./plots/st_thin_svd_f64_plot.png" alt="thin singular value decomposition" /></p>
<hr />
<p><img src="./plots/st_eigh_f64_plot.png" alt="self adjoint eigenvalue decomposition" /></p>
<hr />
<p><img src="./plots/st_eig_f64_plot.png" alt="eigenvalue decomposition" /></p>
<hr />
<h2 id="c32"><a class="header" href="#c32">c32</a></h2>
<p><img src="./plots/st_cholesky_c32_plot.png" alt="cholesky" /></p>
<hr />
<p><img src="./plots/st_qr_c32_plot.png" alt="qr" /></p>
<hr />
<p><img src="./plots/st_piv_qr_c32_plot.png" alt="qr with column pivoting" /></p>
<hr />
<p><img src="./plots/st_lu_c32_plot.png" alt="lu with partial pivoting" /></p>
<hr />
<p><img src="./plots/st_piv_lu_c32_plot.png" alt="lu with full pivoting" /></p>
<hr />
<p><img src="./plots/st_svd_c32_plot.png" alt="singular value decomposition" /></p>
<hr />
<p><img src="./plots/st_thin_svd_c32_plot.png" alt="thin singular value decomposition" /></p>
<hr />
<p><img src="./plots/st_eigh_c32_plot.png" alt="self adjoint eigenvalue decomposition" /></p>
<hr />
<p><img src="./plots/st_eig_c32_plot.png" alt="eigenvalue decomposition" /></p>
<hr />
<h2 id="c64"><a class="header" href="#c64">c64</a></h2>
<p><img src="./plots/st_cholesky_c64_plot.png" alt="cholesky" /></p>
<hr />
<p><img src="./plots/st_qr_c64_plot.png" alt="qr" /></p>
<hr />
<p><img src="./plots/st_piv_qr_c64_plot.png" alt="qr with column pivoting" /></p>
<hr />
<p><img src="./plots/st_lu_c64_plot.png" alt="lu with partial pivoting" /></p>
<hr />
<p><img src="./plots/st_piv_lu_c64_plot.png" alt="lu with full pivoting" /></p>
<hr />
<p><img src="./plots/st_svd_c64_plot.png" alt="singular value decomposition" /></p>
<hr />
<p><img src="./plots/st_thin_svd_c64_plot.png" alt="thin singular value decomposition" /></p>
<hr />
<p><img src="./plots/st_eigh_c64_plot.png" alt="self adjoint eigenvalue decomposition" /></p>
<hr />
<p><img src="./plots/st_eig_c64_plot.png" alt="eigenvalue decomposition" /></p>
<hr />
<div style="break-before: page; page-break-before: always;"></div><p>the benchmarks were run on an <code>11th gen intel(r) core(tm) i5-11400 @ 2.60ghz</code> with 6 threads (hyperthreading off).</p>
<p>all computations are done on column major matrices.</p>
<p>the plots are normalized so that the <em><code>faer</code></em> line is set to <code>1.0</code>.</p>
<p>higher is better on all the plots.</p>
<p>last updated: 2024-05-25</p>
<h2 id="f32-1"><a class="header" href="#f32-1">f32</a></h2>
<p><img src="./plots/mt_cholesky_f32_plot.png" alt="cholesky" /></p>
<hr />
<p><img src="./plots/mt_qr_f32_plot.png" alt="qr" /></p>
<hr />
<p><img src="./plots/mt_piv_qr_f32_plot.png" alt="qr with column pivoting" /></p>
<hr />
<p><img src="./plots/mt_lu_f32_plot.png" alt="lu with partial pivoting" /></p>
<hr />
<p><img src="./plots/mt_piv_lu_f32_plot.png" alt="lu with full pivoting" /></p>
<hr />
<p><img src="./plots/mt_svd_f32_plot.png" alt="singular value decomposition" /></p>
<hr />
<p><img src="./plots/mt_thin_svd_f32_plot.png" alt="thin singular value decomposition" /></p>
<hr />
<p><img src="./plots/mt_eigh_f32_plot.png" alt="self adjoint eigenvalue decomposition" /></p>
<hr />
<p><img src="./plots/mt_eig_f32_plot.png" alt="eigenvalue decomposition" /></p>
<hr />
<h2 id="f64-1"><a class="header" href="#f64-1">f64</a></h2>
<p><img src="./plots/mt_cholesky_f64_plot.png" alt="cholesky" /></p>
<hr />
<p><img src="./plots/mt_qr_f64_plot.png" alt="qr" /></p>
<hr />
<p><img src="./plots/mt_piv_qr_f64_plot.png" alt="qr with column pivoting" /></p>
<hr />
<p><img src="./plots/mt_lu_f64_plot.png" alt="lu with partial pivoting" /></p>
<hr />
<p><img src="./plots/mt_piv_lu_f64_plot.png" alt="lu with full pivoting" /></p>
<hr />
<p><img src="./plots/mt_svd_f64_plot.png" alt="singular value decomposition" /></p>
<hr />
<p><img src="./plots/mt_thin_svd_f64_plot.png" alt="thin singular value decomposition" /></p>
<hr />
<p><img src="./plots/mt_eigh_f64_plot.png" alt="self adjoint eigenvalue decomposition" /></p>
<hr />
<p><img src="./plots/mt_eig_f64_plot.png" alt="eigenvalue decomposition" /></p>
<hr />
<h2 id="c32-1"><a class="header" href="#c32-1">c32</a></h2>
<p><img src="./plots/mt_cholesky_c32_plot.png" alt="cholesky" /></p>
<hr />
<p><img src="./plots/mt_qr_c32_plot.png" alt="qr" /></p>
<hr />
<p><img src="./plots/mt_piv_qr_c32_plot.png" alt="qr with column pivoting" /></p>
<hr />
<p><img src="./plots/mt_lu_c32_plot.png" alt="lu with partial pivoting" /></p>
<hr />
<p><img src="./plots/mt_piv_lu_c32_plot.png" alt="lu with full pivoting" /></p>
<hr />
<p><img src="./plots/mt_svd_c32_plot.png" alt="singular value decomposition" /></p>
<hr />
<p><img src="./plots/mt_thin_svd_c32_plot.png" alt="thin singular value decomposition" /></p>
<hr />
<p><img src="./plots/mt_eigh_c32_plot.png" alt="self adjoint eigenvalue decomposition" /></p>
<hr />
<p><img src="./plots/mt_eig_c32_plot.png" alt="eigenvalue decomposition" /></p>
<hr />
<h2 id="c64-1"><a class="header" href="#c64-1">c64</a></h2>
<p><img src="./plots/mt_cholesky_c64_plot.png" alt="cholesky" /></p>
<hr />
<p><img src="./plots/mt_qr_c64_plot.png" alt="qr" /></p>
<hr />
<p><img src="./plots/mt_piv_qr_c64_plot.png" alt="qr with column pivoting" /></p>
<hr />
<p><img src="./plots/mt_lu_c64_plot.png" alt="lu with partial pivoting" /></p>
<hr />
<p><img src="./plots/mt_piv_lu_c64_plot.png" alt="lu with full pivoting" /></p>
<hr />
<p><img src="./plots/mt_svd_c64_plot.png" alt="singular value decomposition" /></p>
<hr />
<p><img src="./plots/mt_thin_svd_c64_plot.png" alt="thin singular value decomposition" /></p>
<hr />
<p><img src="./plots/mt_eigh_c64_plot.png" alt="self adjoint eigenvalue decomposition" /></p>
<hr />
<p><img src="./plots/mt_eig_c64_plot.png" alt="eigenvalue decomposition" /></p>
<hr />
<div style="break-before: page; page-break-before: always;"></div><h1 id="matrix-management"><a class="header" href="#matrix-management">Matrix management</a></h1>
<h2 id="creating-a-matrix"><a class="header" href="#creating-a-matrix">Creating a matrix</a></h2>
<p><em><code>faer</code></em> provides several ways to create dense matrices and matrix views.</p>
<p>The main matrix types are <a href="https://docs.rs/faer/latest/faer/mat/struct.Mat.html"><code>Mat</code></a>, <a href="https://docs.rs/faer/latest/faer/mat/struct.MatRef.html"><code>MatRef</code></a> and <a href="https://docs.rs/faer/latest/faer/mat/struct.MatMut.html"><code>MatMut</code></a>,
which can be thought of as being analogous to <code>Vec</code>, <code>&amp;[_]</code> and <code>&amp;mut [_]</code>.</p>
<ul>
<li><a href="https://docs.rs/faer/latest/faer/mat/struct.Mat.html"><code>Mat</code></a> owns its data, provides read-write access to it, and can be resized after creation.</li>
<li><a href="https://docs.rs/faer/latest/faer/mat/struct.MatRef.html"><code>MatRef</code></a> provides read-only access to the underlying data.</li>
<li><a href="https://docs.rs/faer/latest/faer/mat/struct.MatMut.html"><code>MatMut</code></a> provides read-write access to the underlying data.</li>
</ul>
<p>The most flexible way to initialize a matrix is to initialize a zero matrix,
then fill out the values by hand.</p>
<pre><code class="language-rust">use faer::Mat;

let mut a = Mat::&lt;f64&gt;::zeros(4, 3);

for j in 0..a.ncols() {
    for i in 0..a.nrows() {
        a[(i, j)] = 9.0;
    }
}</code></pre>
<p>Given a callable object that outputs the matrix elements, <a href="https://docs.rs/faer/latest/faer/mat/struct.Mat.html#method.from_fn"><code>Mat::from_fn</code></a>, can also be used.</p>
<pre><code class="language-rust">use faer::Mat;

let a = Mat::from_fn(3, 4, |i, j| (i + j) as f64);</code></pre>
<p>For common matrices such as the zero matrix and the identity matrix, shorthands
are provided.</p>
<pre><code class="language-rust">use faer::Mat;

// creates a 10×4 matrix whose values are all `0.0`.
let a = Mat::&lt;f64&gt;::zeros(10, 4);

// creates a 5×4 matrix containing `0.0` except on the main diagonal,
// which contains `1.0` instead.
let a = Mat::&lt;f64&gt;::identity(5, 4);</code></pre>
<p>In some cases, users may wish to avoid the cost of initializing the matrix to zero,
in which case, unsafe code may be used to allocate an uninitialized matrix, which
can then be filled out before it's used.</p>
<pre><code class="language-rust">// `a` is initially a 0×0 matrix.
let mut a = Mat::&lt;f64&gt;::with_capacity(4, 3);

// `a` is now a 4×3 matrix, whose values are uninitialized.
unsafe { a.set_dims(4, 3) };

for j in 0..a.ncols() {
    for i in 0..a.nrows() {
        // we cannot write `a[(i, j)] = 9.0`, as that would
        // create a reference to uninitialized data,
        // which is currently disallowed by Rust.
        a.write(i, j, 9.0);

        // we can also skip the bound checks using
        // read_unchecked and write_unchecked
        unsafe { a.write_unchecked(i, j, 9.0) };
    }
}</code></pre>
<h2 id="creating-a-matrix-view"><a class="header" href="#creating-a-matrix-view">Creating a matrix view</a></h2>
<p>In some situations, it may be desirable to create a matrix view over existing
data.
In that case, we can use <a href="https://docs.rs/faer/latest/faer/mat/struct.MatRef.html"><code>MatRef</code></a> (or <a href="https://docs.rs/faer/latest/faer/mat/struct.MatMut.html"><code>MatMut</code></a> for
mutable views).</p>
<p>They can be created in a safe way using:</p>
<ul>
<li><a href="https://docs.rs/faer/latest/faer/mat/fn.from_column_major_slice.html"><code>mat::from_column_major_slice</code></a>,</li>
<li><a href="https://docs.rs/faer/latest/faer/mat/fn.from_row_major_slice.html"><code>mat::from_row_major_slice</code></a>,</li>
<li><a href="https://docs.rs/faer/latest/faer/mat/fn.from_column_major_slice_mut.html"><code>mat::from_column_major_slice_mut</code></a>,</li>
<li><a href="https://docs.rs/faer/latest/faer/mat/fn.from_row_major_slice_mut.html"><code>mat::from_row_major_slice_mut</code></a>,</li>
</ul>
<p>for contiguous matrix storage, or:</p>
<ul>
<li><a href="https://docs.rs/faer/latest/faer/mat/fn.from_column_major_slice_with_stride.html"><code>mat::from_column_major_slice_with_stride</code></a>,</li>
<li><a href="https://docs.rs/faer/latest/faer/mat/fn.from_row_major_slice_with_stride.html"><code>mat::from_row_major_slice_with_stride</code></a>,</li>
<li><a href="https://docs.rs/faer/latest/faer/mat/fn.from_column_major_slice_with_stride_mut.html"><code>mat::from_column_major_slice_with_stride_mut</code></a>,</li>
<li><a href="https://docs.rs/faer/latest/faer/mat/fn.from_row_major_slice_with_stride_mut.html"><code>mat::from_row_major_slice_with_stride_mut</code></a>,</li>
</ul>
<p>for strided matrix storage.</p>
<p>An unsafe lower level pointer API is also provided for handling uninitialized data
or arbitrary strides using <a href="https://docs.rs/faer/latest/faer/mat/fn.from_raw_parts.html"><code>mat::from_raw_parts</code></a> and <a href="https://docs.rs/faer/latest/faer/mat/fn.from_raw_parts_mut.html"><code>mat::from_raw_parts_mut</code></a>.</p>
<h2 id="converting-to-a-view"><a class="header" href="#converting-to-a-view">Converting to a view</a></h2>
<p>A <a href="https://docs.rs/faer/latest/faer/mat/struct.Mat.html"><code>Mat</code></a> instance <code>m</code> can be converted to <a href="https://docs.rs/faer/latest/faer/mat/struct.MatRef.html"><code>MatRef</code></a> or <a href="https://docs.rs/faer/latest/faer/mat/struct.MatMut.html"><code>MatMut</code></a> by writing <a href="https://docs.rs/faer/latest/faer/type.Mat.html#method.as_ref"><code>m.as_ref()</code></a>
or <a href="https://docs.rs/faer/latest/faer/type.Mat.html#method.as_mut"><code>m.as_mut()</code></a>.</p>
<h2 id="reborrowing-a-mutable-view"><a class="header" href="#reborrowing-a-mutable-view">Reborrowing a mutable view</a></h2>
<p>Immutable matrix views can be freely copied around, since they are non-owning
wrappers around a pointer and the matrix dimensions/strides.</p>
<p>Mutable matrices however are limited by Rust's borrow checker. Copying them
would be unsound since only a single active mutable view is allowed at a time.</p>
<p>This means the following code does not compile.</p>
<pre><code class="language-rust">use faer::{Mat, MatMut};

fn takes_view_mut(m: MatMut&lt;f64&gt;) {}

let mut a = Mat::&lt;f64&gt;::new();
let view = a.as_mut();

takes_view_mut(view);

// This would have failed to compile since `MatMut` is never `Copy`
// takes_view_mut(view);</code></pre>
<p>The alternative is to temporarily give up ownership over the data, by creating
a view with a shorter lifetime, then recovering the ownership when the view is
no longer being used.</p>
<p>This is also called reborrowing.</p>
<pre><code class="language-rust">use faer::{Mat, MatMut, MatRef};
use reborrow::*;

fn takes_view(m: MatRef&lt;f64&gt;) {}
fn takes_view_mut(m: MatMut&lt;f64&gt;) {}

let mut a = Mat::&lt;f64&gt;::new();
let mut view = a.as_mut();

takes_view_mut(view.rb_mut());
takes_view_mut(view.rb_mut());
takes_view(view.rb()); // We can also reborrow immutably

{
    let short_view = view.rb_mut();

    // This would have failed to compile since we can't use the original view
    // while the reborrowed view is still being actively used
    // takes_view_mut(view);

    takes_view_mut(short_view);
}

// We can once again use the original view
takes_view_mut(view.rb_mut());

// Or consume it to convert it to an immutable view
takes_view(view.into_const());</code></pre>
<h2 id="splitting-a-matrix-view-slicing-a-submatrix"><a class="header" href="#splitting-a-matrix-view-slicing-a-submatrix">Splitting a matrix view, slicing a submatrix</a></h2>
<p>A matrix view can be split up along its row axis, column axis or both.
This is done using <a href="https://docs.rs/faer/latest/faer/mat/struct.MatRef.html#method.split_at_row"><code>MatRef::split_at_row</code></a>, <a href="https://docs.rs/faer/latest/faer/mat/struct.MatRef.html#method.split_at_col"><code>MatRef::split_at_col</code></a> or
<a href="https://docs.rs/faer/latest/faer/mat/struct.MatRef.html#method.split_at"><code>MatRef::split_at</code></a> (or <a href="https://docs.rs/faer/latest/faer/mat/struct.MatMut.html#method.split_at_row_mut"><code>MatMut::split_at_row_mut</code></a>, <a href="https://docs.rs/faer/latest/faer/mat/struct.MatMut.html#method.split_at_col_mut"><code>MatMut::split_at_col_mut</code></a> or
<a href="https://docs.rs/faer/latest/faer/mat/struct.MatMut.html#method.split_at_mut"><code>MatMut::split_at_mut</code></a>).</p>
<p>These functions take the middle index at which the split is performed, and return
the two sides (in top/bottom or left/right order) or the four corners (top
left, top right, bottom left, bottom right)</p>
<p>We can also take a submatrix using <a href="https://docs.rs/faer/latest/faer/mat/struct.MatRef.html#method.subrows"><code>MatRef::subrows</code></a>, <a href="https://docs.rs/faer/latest/faer/mat/struct.MatRef.html#method.subcols"><code>MatRef::subcols</code></a> or
<a href="https://docs.rs/faer/latest/faer/mat/struct.MatRef.html#method.submatrix"><code>MatRef::submatrix</code></a> (or <a href="https://docs.rs/faer/latest/faer/mat/struct.MatMut.html#method.subrows_mut"><code>MatMut::subrows_mut</code></a>, <a href="https://docs.rs/faer/latest/faer/mat/struct.MatMut.html#method.subcols_mut"><code>MatMut::subcols_mut</code></a> or
<a href="https://docs.rs/faer/latest/faer/mat/struct.MatMut.html#method.submatrix_mut"><code>MatMut::submatrix_mut</code></a>).</p>
<p>Alternatively, we can also use <a href="https://docs.rs/faer/latest/faer/mat/struct.MatRef.html#method.get"><code>MatRef::get</code></a> or <a href="https://docs.rs/faer/latest/faer/mat/struct.MatMut.html#method.get_mut"><code>MatMut::get_mut</code></a>, which take
as parameters the row and column ranges.</p>
<h3 id="warning"><a class="header" href="#warning">⚠️Warning⚠️</a></h3>
<p>Note that <a href="https://docs.rs/faer/latest/faer/mat/struct.MatRef.html#method.submatrix"><code>MatRef::submatrix</code></a> (and <a href="https://docs.rs/faer/latest/faer/mat/struct.MatRef.html#method.subrows"><code>MatRef::subrows</code></a>, <a href="https://docs.rs/faer/latest/faer/mat/struct.MatRef.html#method.subcols"><code>MatRef::subcols</code></a>) takes
as a parameter, the first row and column of the submatrix, then the number
of rows and columns of the submatrix.</p>
<p>On the other hand, <a href="https://docs.rs/faer/latest/faer/mat/struct.MatRef.html#method.get"><code>MatRef::get</code></a> takes a range from the first row and column
to the last row and column.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="matrix-arithmetic-operations"><a class="header" href="#matrix-arithmetic-operations">Matrix arithmetic operations</a></h1>
<p><em><code>faer</code></em> matrices implement most of the arithmetic operators, so two matrices
can be added simply by writing <code>&amp;a + &amp;b</code>, the result of the expression is a
<code>faer::Mat</code>, which allows simple chaining of operations (e.g. <code>(&amp;a + faer::scale(3.0) * &amp;b) * &amp;c</code>), although
at the cost of allocating temporary matrices.</p>
<p>temporary allocations can be avoided by using the <a href="https://docs.rs/faer/latest/faer/macro.zipped.html"><code>zipped!</code></a> api:</p>
<pre><code class="language-rust">use faer::{Mat, zipped, unzipped};

let a = Mat::&lt;f64&gt;::zeros(4, 3);
let b = Mat::&lt;f64&gt;::zeros(4, 3);
let mut c = Mat::&lt;f64&gt;::zeros(4, 3);

// Sums `a` and `b` and stores the result in `c`.
zipped!(&amp;mut c, &amp;a, &amp;b).for_each(|unzipped!(c, a, b)| *c = *a + *b);

// Sums `a`, `b` and `c` into a new matrix `d`.
let d = zipped!(&amp;mut c, &amp;a, &amp;b).map(|unzipped!(c, a, b)| *a + *b + *c);</code></pre>
<p>for matrix multiplication, the non-allocating api in-place is provided in the
<a href="https://docs.rs/faer/latest/faer/linalg/matmul/index.html"><code>faer::linalg::matmul</code></a> module.</p>
<pre><code class="language-rust">use faer::{Mat, Parallelism};
use faer::linalg::matmul::matmul;

let a = Mat::&lt;f64&gt;::zeros(4, 3);
let b = Mat::&lt;f64&gt;::zeros(3, 5);

let mut c = Mat::&lt;f64&gt;::zeros(4, 5);

// Computes `faer::scale(3.0) * &amp;a * &amp;b` and stores the result in `c`.
matmul(c.as_mut(), a.as_ref(), b.as_ref(), None, 3.0, Parallelism::None);

// Computes `faer::scale(3.0) * &amp;a * &amp;b + 5.0 * &amp;c` and stores the result in `c`.
matmul(c.as_mut(), a.as_ref(), b.as_ref(), Some(5.0), 3.0, Parallelism::None);</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="solving-a-linear-system"><a class="header" href="#solving-a-linear-system">Solving a Linear System</a></h1>
<p>several applications require solving a linear system of the form \(A x = b\).
the recommended method can vary depending on the properties of \(A\), and the
desired numerical accuracy.</p>
<h2 id="a-is-triangular"><a class="header" href="#a-is-triangular">\(A\) is triangular</a></h2>
<p>in this case, one can use \(A\) and \(b\) directly to find \(x\), using the functions
provided in <a href="https://docs.rs/faer/latest/faer/linalg/triangular_solve/index.html"><code>faer::linalg::triangular_solve</code></a>.</p>
<pre><code class="language-rust">use faer::{Mat, Parallelism};
use faer::linalg::triangular_solve::solve_lower_triangular_in_place;

let a = Mat::&lt;f64&gt;::from_fn(4, 4, |i, j| if i &gt;= j { 1.0 } else { 0.0 });
let b = Mat::&lt;f64&gt;::from_fn(4, 2, |i, j| (i - j) as f64);

let mut x = Mat::&lt;f64&gt;::zeros(4, 2);
x.copy_from(&amp;b);
solve_lower_triangular_in_place(a.as_ref(), x.as_mut(), Parallelism::None);

// x now contains the approximate solution</code></pre>
<p>in the case where \(A\) has a unit diagonal, one can use
<a href="https://docs.rs/faer/latest/faer/linalg/triangular_solve/fn.solve_unit_lower_triangular_in_place.html"><code>solve_unit_lower_triangular_in_place</code></a>, which avoids reading the diagonal, and
instead implicitly uses the value <code>1.0</code> as a replacement.</p>
<h2 id="a-is-real-symmetriccomplex-hermitian"><a class="header" href="#a-is-real-symmetriccomplex-hermitian">\(A\) is real-symmetric/complex-Hermitian</a></h2>
<p>if \(A\) is Hermitian and positive definite, users can use the cholesky llt
decomposition.</p>
<pre><code class="language-rust">use faer::{mat, Side};
use faer::prelude::*;

let a = mat![
    [10.0, 2.0],
    [2.0, 10.0f64],
];
let b = mat![[15.0], [-3.0f64]];

// Compute the Cholesky decomposition,
// reading only the lower triangular half of the matrix.
let llt = a.cholesky(Side::Lower).unwrap();

let x = llt.solve(&amp;b);</code></pre>
<h3 id="low-level-api"><a class="header" href="#low-level-api">Low level API</a></h3>
<p>alternatively, a lower-level api could be used to avoid temporary allocations.
the corresponding code for other decompositions follows the same pattern, so we
will skip similar examples for the remainder of this page.</p>
<pre><code class="language-rust">use faer::{mat, Parallelism, Conj};
use faer::linalg::cholesky::llt::compute::cholesky_in_place_req;
use faer::linalg::cholesky::llt::compute::{cholesky_in_place, LltRegularization, LltParams};
use faer::linalg::cholesky::llt::solve::solve_in_place_req;
use faer::linalg::cholesky::llt::solve::solve_in_place_with_conj;
use dyn_stack::{PodStack, GlobalPodBuffer};

let a = mat![
    [10.0, 2.0],
    [2.0, 10.0f64],
];
let mut b = mat![[15.0], [-3.0f64]];

let mut llt = Mat::&lt;f64&gt;::zeros(2, 2);
let no_par = Parallelism::None;

// Compute the size and alignment of the required scratch space
let cholesky_memory = cholesky_in_place_req::&lt;f64&gt;(
    a.nrows(),
    Parallelism::None,
    LltParams::default(),
).unwrap();
let solve_memory = solve_in_place_req::&lt;f64&gt;(
    a.nrows(),
    b.ncols(),
    Parallelism::None,
).unwrap();

// Allocate the scratch space
let mut memory = GlobalPodBuffer::new(cholesky_memory.or(solve_memory));
let mut stack = PodStack::new(&amp;mut mem);

// Compute the decomposition
llt.copy_from(&amp;a);
cholesky_in_place(
    llt.as_mut(),
    LltRegularization::default(), // no regularization
    no_par,
    stack.rb_mut(),               // scratch space
    LltParams::default(),         // default settings
);
// Solve the linear system
solve_in_place_with_conj(llt.as_ref(), Conj::No, b.as_mut(), no_par, stack);</code></pre>
<p>If \(A\) is not positive definite, the Bunch-Kaufman LBLT decomposition is recommended instead.</p>
<pre><code class="language-rust">use faer::{mat, Side};
use faer::prelude::*;

let a = mat![
    [10.0, 2.0],
    [2.0, -10.0f64],
];
let b = mat![[15.0], [-3.0f64]];

// Compute the Bunch-Kaufman LBLT decomposition,
// reading only the lower triangular half of the matrix.
let lblt = a.lblt(Side::Lower);

let x = lblt.solve(&amp;b);</code></pre>
<h2 id="a-is-square"><a class="header" href="#a-is-square">\(A\) is square</a></h2>
<p>for a square matrix \(A\), we can use the lu decomposition with partial pivoting,
or the full pivoting variant which is slower but can be more accurate when the
matrix is nearly singular.</p>
<pre><code class="language-rust">use faer::mat;
use faer::prelude::*;

let a = mat![
    [10.0, 3.0],
    [2.0, -10.0f64],
];
let b = mat![[15.0], [-3.0f64]];

// Compute the LU decomposition with partial pivoting,
let plu = a.partial_piv_lu();
let x1 = plu.solve(&amp;b);

// or the LU decomposition with full pivoting.
let flu = a.full_piv_lu();
let x2 = flu.solve(&amp;b);</code></pre>
<h2 id="a-is-a-tall-matrix-least-squares-solution"><a class="header" href="#a-is-a-tall-matrix-least-squares-solution">\(A\) is a tall matrix (least squares solution)</a></h2>
<p>when the linear system is over-determined, an exact solution may not
necessarily exist, in which case we can get a best-effort result by computing
the least squares solution.
that is, the solution that minimizes \(||A x - b||\).</p>
<p>this can be done using the qr decomposition.</p>
<pre><code class="language-rust">use faer::mat;
use faer::prelude::*;

let a = mat![
    [10.0, 3.0],
    [2.0, -10.0],
    [3.0, -45.0f64],
];
let b = mat![[15.0], [-3.0], [13.1f64]];

// Compute the QR decomposition.
let qr = a.qr();
let x = qr.solve_lstsq(&amp;b);</code></pre>
<h2 id="computing-the-singular-value-decomposition"><a class="header" href="#computing-the-singular-value-decomposition">computing the singular value decomposition</a></h2>
<pre><code class="language-rust">use faer::mat;
use faer::prelude::*;

let a = mat![
    [10.0, 3.0],
    [2.0, -10.0],
    [3.0, -45.0f64],
];

// Compute the SVD decomposition.
let svd = a.svd();
// Compute the thin SVD decomposition.
let svd = a.thin_svd();
// Compute the singular values.
let svd = a.singular_values();</code></pre>
<h2 id="computing-the-eigenvalue-decomposition"><a class="header" href="#computing-the-eigenvalue-decomposition">computing the eigenvalue decomposition</a></h2>
<pre><code class="language-rust">use faer::mat;
use faer::prelude::*;
use faer::complex_native::c64;

let a = mat![
    [10.0, 3.0],
    [2.0, -10.0f64],
];

// Compute the eigendecomposition.
let evd = a.eigendecomposition::&lt;c64&gt;();

// Compute the eigenvalues.
let evd = a.eigenvalues::&lt;c64&gt;();

// Compute the eigendecomposition assuming `a` is Hermitian.
let evd = a.selfadjoint_eigendecomposition();

// Compute the eigenvalues assuming `a` is Hermitian.
let evd = a.selfadjoint_eigenvalues();</code></pre>
<div style="break-before: page; page-break-before: always;"></div><p>conversions from/to external library types is provided separately from <em><code>faer</code></em> itself, in the <em><code>faer-ext</code></em> crate.</p>
<h1 id="note"><a class="header" href="#note">note</a></h1>
<p>only matrix view types can be converted. owning matrices can't be converted due to <em><code>faer</code></em> using a different allocation scheme from <strong><code>nalgebra</code></strong> and <em><code>ndarray</code></em>.</p>
<h1 id="converting-tofrom-nalgebra-matrices"><a class="header" href="#converting-tofrom-nalgebra-matrices">converting to/from <em><code>nalgebra</code></em> matrices</a></h1>
<p>conversion from <em><code>nalgebra</code></em> types is done by enabling the <code>nalgebra</code> feature and using the <a href="https://docs.rs/faer/latest/faer/trait.IntoFaer.html"><code>IntoFaer</code></a> and <a href="https://docs.rs/faer-ext/latest/faer_ext/trait.IntoFaerComplex.html"><code>IntoFaerComplex</code></a> traits.<br />
conversion to <em><code>nalgebra</code></em> types is enabled by the same feature and uses the <a href="https://docs.rs/faer/latest/faer/trait.IntoNalgebra.html"><code>IntoNalgebra</code></a> and <a href="https://docs.rs/faer-ext/latest/faer_ext/trait.IntoNalgebraComplex.html"><code>IntoNalgebraComplex</code></a> traits.</p>
<pre><code class="language-rust">use faer::Mat;
use faer_ext::*;

let mut I_faer = Mat::&lt;f32&gt;::identity(8, 7);
let mut I_nalgebra = nalgebra::DMatrix::&lt;f32&gt;::identity(8, 7);

assert!(I_nalgebra.view_range(.., ..).into_faer() == I_faer);
assert!(I_faer.as_ref().into_nalgebra() == I_nalgebra);

assert!(I_nalgebra.view_range_mut(.., ..).into_faer() == I_faer);
assert!(I_faer.as_mut().into_nalgebra() == I_nalgebra);</code></pre>
<h1 id="converting-tofrom-ndarray-matrices"><a class="header" href="#converting-tofrom-ndarray-matrices">converting to/from <em><code>ndarray</code></em> matrices</a></h1>
<p>conversion from <em><code>ndarray</code></em> types is done by enabling the <code>ndarray</code> feature and using the <a href="https://docs.rs/faer/latest/faer/trait.IntoFaer.html"><code>IntoFaer</code></a> and <a href="https://docs.rs/faer-ext/latest/faer_ext/trait.IntoFaerComplex.html"><code>IntoFaerComplex</code></a> traits.<br />
conversion to <em><code>ndarray</code></em> types is enabled by the same feature and uses the <a href="https://docs.rs/faer/latest/faer/trait.IntoNdarray.html"><code>IntoNdarray</code></a> and <a href="https://docs.rs/faer-ext/latest/faer_ext/trait.IntoNdarrayComplex.html"><code>IntoNdarrayComplex</code></a> traits.</p>
<pre><code class="language-rust">use faer::Mat;
use faer_ext::*;

let mut I_faer = Mat::&lt;f32&gt;::identity(8, 7);
let mut I_ndarray = ndarray::Array2::&lt;f32&gt;::zeros([8, 7]);
I_ndarray.diag_mut().fill(1.0);

assert_matrix_eq!(I_ndarray.view().into_faer(), I_faer, comp = exact);
assert!(I_faer.as_ref().into_ndarray() == I_ndarray);

assert!(I_ndarray.view_mut().into_faer() == I_faer);
assert!(I_faer.as_mut().into_ndarray() == I_ndarray);</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="sparse-linear-algebra"><a class="header" href="#sparse-linear-algebra">sparse linear algebra</a></h1>
<p>a sparse matrix is a matrix for which the majority of entries are zeros.
by skipping those entries and only processing the non-zero elements, along with their positions in the matrix, we can obtain a reduction in memory usage and amount of computations.</p>
<p>since the sparse data structures and algorithms can often deal with very large matrices and use an unpredictable amount of memory, <em><code>faer</code></em> tries to be more robust with respect to handling out of memory conditions.
due to this, most of the sparse <em><code>faer</code></em> routines that require memory allocations will return a result that could indicate whether the matrix was too large to be stored.</p>
<p>most of the errors can be propagated to the caller and handled at the top level, or handled at some point by switching to a method that requires less memory usage.</p>
<h2 id="creating-a-sparse-matrix"><a class="header" href="#creating-a-sparse-matrix">creating a sparse matrix</a></h2>
<p>just like how dense matrices can be column-major or row-major, sparse matrices also come in two layouts.
The first one is [compressed] sparse column layout (csc) and the second is [compressed] sparse row layout (csr).
most of the <em><code>faer</code></em> sparse algorithms operate on csc matrices, with csr matrices requiring a preliminary conversion step.</p>
<p>the csc (resp. csr) layout of a matrix \(A\) is composed of three components:</p>
<ul>
<li>the column pointers (resp. row pointers),</li>
<li>(optional) the number of non-zero elements per column (resp. row), in which case we say the matrix is in an uncompressed mode,</li>
<li>the row indices (resp. column indices),</li>
<li>the numerical values</li>
</ul>
<p>the column pointers are in an array of size <code>A.ncols() + 1</code>.<br />
the row indices are in an array of size <code>col_ptr[A.ncols()]</code>, such that when the matrix is compressed, <code>row_indices[col_ptr[j]..col_ptr[j + 1]]</code> contains the indices of the non-zero rows in column <code>j</code>.
when the matrix is uncompressed, the row indices are instead contained in <code>row_indices[col_ptr[j]..col_ptr[j] + nnz_per_col[j]]</code>.<br />
the numerical values are in an array of the same size as the row indices, and indicate the numerical value stored at the corresponding index.</p>
<p>let us take the following matrix as an example:</p>
<pre><code class="language-notcode">[[0.0, 2.0, 4.0, 7.0]
 [1.0, 0.0, 5.0, 0.0]
 [0.0, 3.0, 6.0, 0.0]]
</code></pre>
<p>in csc layout, the matrix would be stored as follows:</p>
<pre><code class="language-notcode">column pointers = [0, 1,    3,       6, 7]
row indices     = [1, 0, 2, 0, 1, 2, 0]
values          = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0]
</code></pre>
<p>in csr layout, it would be stored as follows:</p>
<pre><code class="language-notcode">row pointers    = [0,       3,    5,    7]
column indices  = [1, 2, 3, 0, 2, 1, 2]
values          = [2.0, 4.0, 7.0, 1.0, 5.0, 3.0, 6.0]
</code></pre>
<p>csc matrices require the row indices in each column to be sorted and contain no duplicates, and matrices created by <em><code>faer</code></em> will respect that unless otherwise specified.
the same is true for csr matrices.<br />
some algorithms specifically don't strictly require sorted indices, such as the matrix decomposition algorithms. in which case <em><code>faer</code></em> provides an escape hatch for users that wish to avoid the overhead of sorting their input data.</p>
<p>the simplest way to create sparse matrices is to use the <a href="https://docs.rs/faer/latest/faer/sparse/struct.SparseColMat.html#method.try_new_from_triplets"><code>SparseColMat::try_new_from_triplets</code></a> (or <a href="https://docs.rs/faer/latest/faer/sparse/struct.SparseRowMat.html#method.try_new_from_triplets"><code>SparseRowMat::try_new_from_triplets</code></a>) constructor, which takes as input a potentially unsorted list of tuples containing the row index, column index and numerical value of each entry.
entries with the same row and column indices are added together. <a href="https://docs.rs/faer/latest/faer/sparse/struct.SparseColMat.html#method.try_new_from_nonnegative_triplets"><code>SparseColMat::try_new_from_nonnegative_triplets</code></a> can also be used, which skips entries containins a negative row or column index.</p>
<p>for problems where the sparsity pattern doesn't change as often as the numerical values, the symbolic and numeric parts can be decoupled using <a href="https://docs.rs/faer/latest/faer/sparse/struct.SymbolicSparseColMat.html#method.try_new_from_indices"><code>SymbolicSparseColMat::try_new_from_indices</code></a> (or <a href="https://docs.rs/faer/latest/faer/sparse/struct.SymbolicSparseColMat.html#method.try_new_from_nonnegative_indices"><code>SymbolicSparseColMat::try_new_from_nonnegative_indices</code></a>) along with <a href="https://docs.rs/faer/latest/faer/sparse/struct.SparseColMat.html#method.new_from_order_and_values"><code>SparseColMat::new_from_order_and_values</code></a>.</p>
<pre><code class="language-rust">use faer::sparse::*;

let a = SparseColMat::&lt;usize, f64&gt;::try_new_from_triplets(
    3,
    4,
    &amp;[
        (1, 0, 1.0),
        (0, 1, 2.0),
        (2, 1, 3.0),
        (0, 2, 4.0),
        (1, 2, 5.0),
        (2, 2, 6.0),
        (0, 3, 7.0),
    ],
);

let a = match a {
    Ok(a) =&gt; a,
    Err(err) =&gt; match err {
        CreationError::Generic(err) =&gt; return Err(err),
        CreationError::OutOfBounds { row, col } =&gt; {
            panic!("some of the provided indices exceed the size of the matrix.")
        }
    },
};</code></pre>
<p>in the case where users want to create their matrix directly from the components, <a href="https://docs.rs/faer/latest/faer/sparse/struct.SymbolicSparseColMat.html#method.new_checked"><code>SymbolicSparseColMat::new_checked</code></a>, <a href="https://docs.rs/faer/latest/faer/sparse/struct.SymbolicSparseColMat.html#method.new_unsorted_checked"><code>SymbolicSparseColMat::new_unsorted_checked</code></a> or <a href="https://docs.rs/faer/latest/faer/sparse/struct.SymbolicSparseColMat.html#method.new_unchecked"><code>SymbolicSparseColMat::new_unchecked</code></a> can be used to respectively create a matrix after checking that it satisfies the validity requirements, creating a matrix after skipping the sorted indices requirement, or skipping all checks altogether.</p>
<p>just like dense matrices, sparse matrices also come in three variants. an owning kind (<a href="https://docs.rs/faer/latest/faer/sparse/struct.SparseColMat.html"><code>SparseColMat</code></a>), a reference kind (<a href="https://docs.rs/faer/latest/faer/sparse/struct.SparseColMatRef.html"><code>SparseColMatRef</code></a>) and a mutable reference kind (<a href="https://docs.rs/faer/latest/faer/sparse/struct.SparseColMatMut.html"><code>SparseColMatMut</code></a>).</p>
<p>note that mutable sparse matrix views do not allow modifying the sparsity structure. only the numerical values are modifiable through mutable views.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="matrix-arithmetic-operations-1"><a class="header" href="#matrix-arithmetic-operations-1">matrix arithmetic operations</a></h1>
<p><code>faer</code> matrices implement most of the arithmetic operators, so two matrices
can be added simply by writing <code>&amp;a + &amp;b</code>, the result of the expression is a
<code>faer::SparseColMat</code> or <code>faer::SparseRowMat</code>, which allows simple chaining of operations (e.g. <code>(&amp;a - &amp;b) * &amp;c</code>), although
at the cost of allocating temporary matrices.</p>
<p>for more complicated use cases, users are encouraged to preallocate the storage for the temporaries with the corresponding sparsity structure and use <a href="https://docs.rs/faer/latest/faer/sparse/ops/fn.binary_op_assign_into.html"><code>faer::sparse::ops::binary_op_assign_into</code></a> or <a href="https://docs.rs/faer-core/latest/faer_core/sparse/ops/fn.ternary_op_assign_into.html"><code>faer::modules::core::ternary_op_assign_into</code></a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="solving-a-linear-system-1"><a class="header" href="#solving-a-linear-system-1">solving a linear system</a></h1>
<p>just like for dense matrices, <em><code>faer</code></em> provides several sparse matrix decompositions for solving linear systems \(Ax = b\), where \(A\) is sparse and \(b\) and \(x\) are dense.
these typically come in two variants, supernodal and simplicial.
the variant is selected automatically depending on the sparsity structure of the matrix.
and although the lower level api provides a way to tune the selection options, it is currently not fully documented.</p>
<h2 id="a-is-triangular-1"><a class="header" href="#a-is-triangular-1">\(A\) is triangular</a></h2>
<p><a href="https://docs.rs/faer/latest/faer/sparse/struct.SparseColMat.html#method.sp_solve_lower_triangular_in_place"><code>faer::sparse::FaerSparseMat::sp_solve_lower_triangular_in_place</code></a> can be used, or similar methods for when the diagonal is unit and/or the matrix is upper triangular.</p>
<h2 id="a-is-real-symmetriccomplex-hermitian-and-positive-definite"><a class="header" href="#a-is-real-symmetriccomplex-hermitian-and-positive-definite">\(A\) is real-symmetric/complex-Hermitian and positive definite</a></h2>
<p>If \(A\) is Hermitian and positive definite, users can use the <a href="https://docs.rs/faer/latest/faer/sparse/struct.SparseColMat.html#method.sp_cholesky">cholesky llt decomposition</a>.</p>
<pre><code class="language-rust">use faer::prelude::*;
use faer::sparse::FaerSparseMat;
use faer::Side;

let a = SparseColMat::&lt;usize, f64&gt;::try_new_from_triplets(
    2,
    2,
    &amp;[
        (0, 0, 10.0),
        (1, 0, 2.0),
        (0, 1, 2.0),
        (1, 1, 10.0),
    ],
).unwrap();
let b = mat![[15.0], [-3.0f64]];

let llt = a.sp_cholesky(Side::Lower).unwrap();
let x = llt.solve(&amp;b);</code></pre>
<h2 id="a-is-square-1"><a class="header" href="#a-is-square-1">\(A\) is square</a></h2>
<p>for a square matrix \(A\), we can use the <a href="https://docs.rs/faer/latest/faer/sparse/struct.SparseColMat.html#method.sp_lu">lu decomposition with partial pivoting</a>.</p>
<pre><code class="language-rust">use faer::prelude::*;
use faer::sparse::FaerSparseMat;

let a = SparseColMat::&lt;usize, f64&gt;::try_new_from_triplets(
    2,
    2,
    &amp;[
        (0, 0, 10.0),
        (1, 0, 2.0),
        (0, 1, 4.0),
        (1, 1, 20.0),
    ],
).unwrap();
let b = mat![[15.0], [-3.0f64]];

let lu = a.sp_lu().unwrap();
let x = lu.solve(&amp;b);</code></pre>
<h2 id="a-is-a-tall-matrix-least-squares-solution-1"><a class="header" href="#a-is-a-tall-matrix-least-squares-solution-1">\(A\) is a tall matrix (least squares solution)</a></h2>
<p>when the linear system is over-determined, an exact solution may not
necessarily exist, in which case we can get a best-effort result by computing
the least squares solution.
that is, the solution that minimizes \(||A x - b||\).</p>
<p>this can be done using the <a href="https://docs.rs/faer/latest/faer/sparse/struct.SparseColMat.html#method.sp_qr">qr decomposition</a>.</p>
<pre><code class="language-rust">use faer::prelude::*;
use faer::sparse::FaerSparseMat;

let a = SparseColMat::&lt;usize, f64&gt;::try_new_from_triplets(
    3,
    2,
    &amp;[
        (0, 0, 10.0),
        (1, 0, 2.0),
        (2, 0, 3.0),
        (0, 1, 4.0),
        (1, 1, 20.0),
        (2, 1, -45.0),
    ],
).unwrap();
let b = mat![[15.0], [-3.0], [33.0f64]];

let qr = a.sp_qr().unwrap();
let x = qr.solve_lstsq(&amp;b);</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="matrix-layout"><a class="header" href="#matrix-layout">matrix layout</a></h1>
<p><em><code>faer</code></em> matrices are composed of a pointer to the data, the shape of the matrix, and its strides. its layout can be described as:</p>
<pre><code class="language-rust">struct MatRef&lt;'a, T&gt; {
  ptr: *const T,
  nrows: usize,
  ncols: usize,
  row_stride: isize,
  col_stride: isize,
  __marker: PhantomData&lt;&amp;'a T&gt;,
}</code></pre>
<p>the row and column count must be non-negative, while strides can be arbitrary.</p>
<p>the matrix is column major when <code>row_stride == 1</code>, or row major when <code>col_stride == 1</code>.</p>
<p>most algorithms in <em><code>faer</code></em> are currently optimized for column major matrices, with the
main exceptions being matrix multiplication and triangular matrix solve.</p>
<p><code>MatMut</code> is essentially the same as <code>MatRef</code>, except mutable, and has the additional constraint that no two elements within its bounds may alias each other.
so for example, if <code>ncols &gt; 0</code> and <code>nrows &gt;= 2</code>, then we can't have <code>row_stride == 0</code>, as that would imply that <code>mat[(0, 0)]</code> and <code>mat[(1, 0)]</code> point to the same memory address,
which can create a soundness hole in the general case.</p>
<p><code>Mat</code> is an owned matrix type, similar to <code>Vec</code>, and is always column major.</p>
<h1 id="move-semantics"><a class="header" href="#move-semantics">move semantics</a></h1>
<p>just like <code>&amp;[T]</code> and <code>&amp;mut [T]</code>, <code>MatRef&lt;'_, T&gt;</code> and <code>MatMut&lt;'a, T&gt;</code> are respectively <code>Copy</code> and <code>!Copy</code>.
this is in order to follow rust's sharing xor mutability rule which lets us avoid a entire class of memory safety issues.</p>
<p>there is, however, a big ergonomics gap between <code>&amp;mut [T]</code> and <code>MatMut&lt;'a, T&gt;</code>. this is due to the fact
that native rust references have built-in language support for reborrowing, which describes the action
of borrowing a parent reference to create a child reference with a shorter lifetime. it can be thought of as a function that takes
<code>&amp;'short mut &amp;'long mut T</code>, and returns <code>&amp;'short mut T</code>.</p>
<p>while the reborrow is active, the original value can't be used. and once the reborrow is no longer being used, the original borrow becomes accessible again.</p>
<p>the compiler automatically determines whether a reference is reborrowed or moved, depending on the context in which it's used.</p>
<p>matrix views try to emulate this behavior using the <code>reborrow::Reborrow[Mut]</code> traits.</p>
<p>built-in reborrowing example:</p>
<pre><code class="language-rust">
fn takes_ref(_: &amp;i32) {}
fn takes_mut(_: &amp;mut i32) {}
fn takes&lt;T&gt;(_: T) {}

let mut i = 0i32;
let ptr = &amp;mut i;

// compiler transforms it to `takes_ref(&amp;*ptr)`
takes_ref(ptr);
// compiler transforms it to `takes_ref(&amp;mut *ptr)`
takes_mut(ptr);
// even though `&amp;mut i32` is not `Copy`,
// we can still use the reference because it was only reborrowed so far
takes_mut(ptr);

// no reborrowing happens here because the corresponding
// `takes` parameter doesn't bind to a reference
takes(ptr);

// doesn't compile. ptr is no longer usable since it was moved
// in the previous call to `takes`.
// takes_mut(ptr);</code></pre>
<p>emulated reborrowing example:</p>
<pre><code class="language-rust">use reborrow::*;

fn takes_ref(_: MatRef&lt;'_, i32&gt;) {}
fn takes_mut(_: MatMut&lt;'_, i32&gt;) {}

let mut ptr = MatMut::&lt;'_, i32&gt;::from_column_major_slice(&amp;mut [], 0, 0);

// immutable reborrow
takes_ref(ptr.rb());
// mutable reborrow
takes_mut(ptr.rb_mut());
// we can still use the reference because it was only reborrowed so far
takes_mut(ptr);

// doesn't compile. ptr is no longer usable since it was moved
// in the previous call to `takes_mut`, since we didn't reborrow
// it manually.
// takes_mut(ptr);</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lifetime-branding"><a class="header" href="#lifetime-branding">lifetime branding</a></h1>
<p>the typical way rust code deals with avoiding runtime bound checks is by using iterators.</p>
<p>this works less well in the case of linear algebra code because the 2d structure sometimes gives us
extra information to work with. and in the case of sparse algorithms, we have to deal with unstructured indices that we
don't necessarily want to repeatedly check.</p>
<p>to work around these limitations, faer primarily uses a technique called lifetime branding.
it revolves around defining unique types distinguished by their lifetimes.</p>
<p>types that differ only in their lifetimes are merged before code generation, so they help
keep the binary size small and allow some unique patterns.</p>
<p>the main example is the <code>Dim&lt;'N&gt;</code> type. it represents a matrix dimension that's fixed at runtime.
the invariant it carries is that for a given lifetime <code>'N</code>, two instances of this type
always have the same value. you can think of it as being similar to const generics (e.g. <code>Dim&lt;const N: usize&gt;</code>),
with the difference being that the size is fixed at runtime instead of comptime.
since <code>Dim&lt;'N&gt;</code> is defined to be invariant in the lifetime <code>'N</code>, this guarantees that
the borrow checker will never coerce an instance of <code>Dim&lt;'a&gt;</code> to <code>Dim&lt;'b&gt;</code>, unless <code>'a</code> and <code>'b</code>
match exactly.</p>
<p>instances of <code>Dim</code> along with their lifetimes can be created with the <code>with_dim!</code> macro.</p>
<p>other types are built around <code>Dim&lt;'N&gt;</code>'s invariant. for example <code>Idx&lt;'N&gt;</code> guarantees
that instances of it will always hold a valid index for the corresponding <code>Dim&lt;'N&gt;</code>,
which in turn implies that bound checks can be soundly elided.</p>
<p><code>MaybeIdx&lt;'N&gt;</code> carries either a valid index or a sentinel value, and <code>IdxInc&lt;'N&gt;</code> carries
an inclusive index, i.e. <code>idx &lt;= n</code>, and is often used for slicing matrices rather than indexing directly.</p>
<pre><code class="language-rust">with_dim!(N, 4);

let i = N.idx(3); // checks the index at creation

// ...

// compiles to a no-op, since the check is enforced at compile time thanks to the lifetime brand.
assert!(i &lt; N);</code></pre>
<h1 id="experimental-covariantcontravariant-lifetime-brands"><a class="header" href="#experimental-covariantcontravariant-lifetime-brands">experimental: covariant/contravariant lifetime brands</a></h1>
<p><em><code>faer</code></em> also has a mostly internal api that makes use of lifetime coercion to unlock new patterns.</p>
<p>the main idea is to generate lifetimes ordered by the <code>outlives</code> relationship that carry new invariants with them.</p>
<p>the main example is <code>Segment&lt;'scope, 'dim, 'range&gt;</code>, which is invariant over all three lifetimes and similarly enforces that instances of the same type hold the same value.
it also guarantees that for a fixed <code>'scope</code>, instances of the type hold a valid range that can be used to slice dimensions of <code>Dim&lt;'n&gt;</code>.</p>
<p>on top of that, given two lifetimes <code>'long_range</code> and <code>'short_range</code> such that <code>'long_range: 'short_range</code> (long outlives short),
<code>Segment</code> guarantees that instances of <code>Segment&lt;'scope, 'dim, 'short_range&gt;</code> carry a segment that's included in that of instances of <code>Segment&lt;'scope, 'dim, 'long_range&gt;</code>.</p>
<p>this fact is used by <code>SegmentIdx&lt;'scope, 'dim, 'range&gt;</code> and <code>SegmentIdxInc&lt;'scope, 'dim, 'range&gt;</code>, which are contravariant over the lifetime <code>'range</code>, and invariant over  the others.
this allows instances of <code>SegmentIdx&lt;'scope, 'dim, 'short_range&gt;</code> to be coerced to instances of <code>SegmentIdx&lt;'scope, 'dim, 'long_range&gt;</code>.</p>
<p>instances of <code>Segment</code> along with their lifetimes can be created with the <code>ghost_tree!</code> macro, which is more complex than <code>Dim</code>, since it needs to express the subset relationships between the different lifetimes.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="simd"><a class="header" href="#simd">simd</a></h1>
<p><em><code>faer</code></em> provides a common interface for generic and composable simd, using the
<em><code>pulp</code></em> crate as a backend. <em><code>pulp</code></em>'s high level api abstracts away the differences
between various instruction sets and provides a common api that's generic over
them (but not the scalar type). this allows users to write a generic implementation
that gets turned into several functions, one for each possible instruction set
among a predetermined subset. finally, the generic implementation can be used along
with an <code>Arch</code> structure that determines the best implementation at runtime.</p>
<p>Here's an example of how <em><code>pulp</code></em> could be used to compute the expression \(x^2 +
2y - |z|\), and store it into an output vector.</p>
<pre><code class="language-rust">use core::iter::zip;

fn compute_expr(out: &amp;mut[f64], x: &amp;[f64], y: &amp;[f64], z: &amp;[f64]) {
    struct Impl&lt;'a&gt; {
        out: &amp;'a mut [f64],
        x: &amp;'a [f64],
        y: &amp;'a [f64],
        z: &amp;'a [f64],
    }

    impl pulp::WithSimd for Impl&lt;'_&gt; {
        type Output = ();

        #[inline(always)]
        fn with_simd&lt;S: pulp::Simd&gt;(self, simd: S) {
            let Self { out, x, y, z } = self;

            let (out_head, out_tail) = S::as_mut_simd_f64s(out);
            let (x_head, x_tail) = S::as_simd_f64s(x);
            let (y_head, y_tail) = S::as_simd_f64s(y);
            let (z_head, z_tail) = S::as_simd_f64s(z);

            let two = simd.splat_f64s(2.0);
            for (out, (&amp;x, (&amp;y, &amp;z))) in zip(
                out_head,
                zip(x_head, zip(y_head, z_head)),
            ) {
                *out = simd.add_f64s(
                    x,
                    simd.sub_f64s(simd.mul_f64s(two, y), simd.abs_f64s(z)),
                );
            }

            for (out, (&amp;x, (&amp;y, &amp;z))) in zip(
                out_tail,
                zip(x_tail, zip(y_tail, z_tail)),
            ) {
                *out = x - 2.0 * y - z.abs();
            }
        }
    }

    pulp::Arch::new().dispatch(Impl { out, x, y, z });
}</code></pre>
<p>there's a lot of things going on at the same time in this code example. let us
go over them step by step.</p>
<p><em><code>pulp</code></em>'s generic simd implementation happens through the <code>WithSimd</code> trait,
which takes <code>self</code> by value to pass in the function parameters. it additionally
provides another parameter to <code>with_simd</code> describing the instruction set being
used. <code>WithSimd::with_simd</code> <em>must</em> be marked with the <code>#[inline(always)]</code> attribute.
forgetting to do so could lead to a significant performance drop.</p>
<p>inside the body of the function, we split up each of <code>out</code>, <code>x</code>, <code>y</code> and
<code>z</code> into two parts using <code>S::as_f64s[_mut]_simd</code>. the first part (<code>head</code>) is a
slice of <code>S::f64s</code>, representing the vectorizable part of the original slice.
The second part (<code>tail</code>) contains the remainder that doesn't fit into a vector
register.</p>
<p>handling the head section is done using vectorized operation. currently these
need to take <code>simd</code> as a parameter, in order to guarantee its availability in a
sound way. this is what allows the api to be safe. the tail section is handled
using scalar operations.</p>
<p>the final step is actually calling into our simd implementation. this is done
by creating an instance of <code>pulp::Arch</code> that performs the runtime detection
(and caches the result, so that future invocations are as fast as possible),
then calling <code>Arch::dispatch</code> which takes a type that implements <code>WithSimd</code>,
and chooses the best simd implementation for it.</p>
<h1 id="memory-alignment"><a class="header" href="#memory-alignment">memory alignment</a></h1>
<p>instead of splitting the input and output slices into two sections
(vectorizable head + non-vectorizable tail), an alternative approach would be
to split them up into three sections instead (vectorizable head + vectorizable
body + vectorizable tail). this can be accomplished using masked loads and
stores, which can speed things up if the slices are <em>similarly aligned</em>.</p>
<p>similarly aligned slices are slices which have the same base address modulo
the byte size of the cpu's vector registers. the simplest way to guarantee this
is to allocate the slices in aligned memory (such that the base address is a
multiple of the register size in bytes), in which case the slices are similarly
aligned, and any subslices of them (with a shared offset and size) will also be
similarly aligned. aligned allocation is done automatically for matrices in <em><code>faer</code></em>,
which helps uphold these guarantees for maximum performance.</p>
<p><em><code>pulp</code></em> itself doesn't currently provide safe memory alignment api for now. but provides an unsafe
abstraction that can be used to build. the <em><code>faer</code></em> implementation is built on top of
<a href="https://docs.rs/pulp/0.19.4/pulp/trait.Simd.html#method.mask_between_m64s"><code>Simd::mask_between_xxx</code></a>, <a href="https://docs.rs/pulp/0.19.4/pulp/trait.Simd.html#method.mask_load_ptr_f64s"><code>Simd::mask_load_ptr_xxx</code></a> and <a href="https://docs.rs/pulp/0.19.4/pulp/trait.Simd.html#method.mask_store_ptr_f64s"><code>Simd::mask_store_ptr_xxx</code></a>, as well as the lifetime branded indexing api.</p>
<p>example using <em><code>faer</code></em> simd:</p>
<pre><code class="language-rust">use faer::ComplexField;
use faer::ColRef;
use faer::ContiguousFwd;
use faer::utils::simd::SimdCtx;
use faer::utils::bound::Dim;
use pulp::Simd;

#[inline(always)]
pub fn dot_product_f32&lt;'N, S: Simd&gt;(
    simd: S,
    lhs: ColRef&lt;'_, f32, Dim&lt;'N&gt;, ContiguousFwd&gt;,
    rhs: ColRef&lt;'_, f32, Dim&lt;'N&gt;, ContiguousFwd&gt;,
) -&gt; f32 {
    let simd = f32::simd_ctx(simd);
    let N = lhs.nrows();
    let align = size_of::&lt;S::f32s&gt;();

    let simd = SimdCtx::&lt;'N, f32, S&gt;::new_align(
        simd,
        N,
        lhs.as_ptr().align_offset(align),
    );

    let mut acc0 = simd.zero();
    let mut acc1 = simd.zero();
    let mut acc2 = simd.zero();
    let mut acc3 = simd.zero();

    let (head, idx4, idx1, tail) = simd.batch_indices::&lt;4&gt;();

    if let Some(i0) = head {
        let l0 = simd.read(lhs, i0);
        let r0 = simd.read(rhs, i0);

        acc0 = simd.mul_add(l0, r0, acc0);
    }
    for [i0, i1, i2, i3] in idx4 {
        let l0 = simd.read(lhs, i0);
        let l1 = simd.read(lhs, i1);
        let l2 = simd.read(lhs, i2);
        let l3 = simd.read(lhs, i3);

        let r0 = simd.read(rhs, i0);
        let r1 = simd.read(rhs, i1);
        let r2 = simd.read(rhs, i2);
        let r3 = simd.read(rhs, i3);

        acc0 = simd.mul_add(l0, r0, acc0);
        acc1 = simd.mul_add(l1, r1, acc1);
        acc2 = simd.mul_add(l2, r2, acc2);
        acc3 = simd.mul_add(l3, r3, acc3);
    }

    for i0 in idx1 {
        let l0 = simd.read(lhs, i0);
        let r0 = simd.read(rhs, i0);

        acc0 = simd.mul_add(l0, r0, acc0);
    }
    if let Some(i0) = tail {
        let l0 = simd.read(lhs, i0);
        let r0 = simd.read(rhs, i0);

        acc0 = simd.mul_add(l0, r0, acc0);
    }
    acc0 = simd.add(acc0, acc1);
    acc2 = simd.add(acc2, acc3);
    acc0 = simd.add(acc0, acc2);

    simd.reduce_sum(acc0)
}</code></pre>
<p>assuming the alignment offset manages to align both <code>lhs</code> and <code>rhs</code>, this version can be much more efficient than the unaligned one.</p>
<p>however, it has a subtle bug that we will explain in the next section.</p>
<h1 id="floating-point-determinism"><a class="header" href="#floating-point-determinism">floating point determinism</a></h1>
<p>when performing reductions on floating point values, it's important to keep in mind that these operations
are typically only approximately associative and commutative. so the rounding error arising from the limited
float precision depends on the order in which the operations are performed.</p>
<p>there is however a useful loophole we can exploit, assume we have a register size of 4, and we want to sum up 23 elements, with a batch size of two registers.</p>
<pre><code class="language-rust">[
    x0, x1, x2, x3,
    x4, x5, x6, x7,
    x8, x9, x10, x11,
    x12, x13, x14, x15,
    x16, x17, x18, x19,
    x20, x21, x22,
]</code></pre>
<p>if we use something similar to the previous algorithm, we get the following intermediate results.</p>
<p>in the case where the alignment offset is <code>0</code>.</p>
<pre><code class="language-rust">// after the batch 2 loop
acc0 = f32x4(
    x0 + x8,
    x1 + x9,
    x2 + x10,
    x3 + x11,
);
acc1 = f32x4(
    x4 + x12,
    x5 + x13,
    x6 + x14,
    x7 + x15,
);

// after the batch 1 loop
acc0 = f32x4(
    (x0 + x8) + x16,
    (x1 + x9) + x17,
    (x2 + x10) + x18,
    (x3 + x11) + x19,
);

// after the tail
acc0 = f32x4(
    ((x0 + x8) + x16) + x20,
    ((x1 + x9) + x17) + x21,
    ((x2 + x10) + x18) + x22,
    ((x3 + x11) + x19) + 0.0,
);

// we add up `acc0` and `acc1`
acc = f32x4(
    (((x0 + x8) + x16) + x20) + (x4 + x12),
    (((x1 + x9) + x17) + x21) + (x5 + x13),
    (((x2 + x10) + x18) + x22) + (x6 + x14),
    (((x3 + x11) + x19) + 0.0) + (x7 + x15),
);

// reduce sum: x =&gt; (x.0 + x.2) + (x.1 + x.3)
acc = (((((x0 + x8) + x16) + x20) + (x4 + x12)) + ((((x1 + x9) + x17) + x21) + (x5 + x13)))
    + ((((x2 + x10) + x18) + x22) + (x6 + x14)) + ((((x3 + x11) + x19) + 0.0) + (x7 + x15))</code></pre>
<p>now let us take the case where the alignment offset is <code>3</code> instead. in this case we pad the array by one element on the left before proceeding.</p>
<p>so it's as if we were working with</p>
<pre><code class="language-rust">[
    0.0, x0, x1, x2,
    x3, x4, x5, x6,
    x7, x8, x9, x10,
    x11, x12, x13, x14,
    x15, x16, x17, x18,
    x19, x20, x21, x22,
]</code></pre>
<p>skipping the intermediate computations, we get the final result</p>
<pre><code class="language-rust">acc = (((((0.0 + x7) + x15) + x19) + (x3 + x11)) + ((((x0 + x8) + x16) + x20) + (x4 + x12)))
    + ((((x1 + x9) + x17) + x21) + (x5 + x13)) + ((((x2 + x10) + x18) + x19) + (x6 + x14))</code></pre>
<p>note that this version of the result contains the term <code>((x2 + x10) + x18) + x19</code>, which doesn't appear
as a term in the original sum unless we assume exact associativity. (commutativity is assumed to be exact for the operations we care about.)</p>
<p>this results in us getting a slightly different result than before, which could lead to hard-to-reproduce bugs if the user expects consistent behavior
between different runs on the same machine. and the alignment happens to be different due to a difference in the memory allocator or the os behavior.</p>
<p>however, if we sum up our elements like this</p>
<pre><code class="language-rust">// after the batch 2 loop
acc0 = f32x4(
    x0 + x8,
    x1 + x9,
    x2 + x10,
    x3 + x11,
);
acc1 = f32x4(
    x4 + x12,
    x5 + x13,
    x6 + x14,
    x7 + x15,
);

// after the batch 1 loop
acc0 = f32x4(
    (x0 + x8) + x16,
    (x1 + x9) + x17,
    (x2 + x10) + x18,
    (x3 + x11) + x19,
);

// after the tail
acc1 = f32x4(
    (x4 + x12) + x20,
    (x5 + x13) + x21,
    (x6 + x14) + x22,
    (x7 + x15) + 0.0,
);

// we add up `acc0` and `acc1`
acc = f32x4(
    ((x0 + x8) + x16) + ((x4 + x12) + x20),
    ((x1 + x9) + x17) + ((x5 + x13) + x21),
    ((x2 + x10) + x18) + ((x6 + x14) + x22),
    ((x3 + x11) + x19) + ((x7 + x15) + 0.0),
);

// reduce sum: x =&gt; (x.0 + x.2) + (x.1 + x.3)
acc = (((x0 + x8) + x16) + ((x4 + x12) + x20) + ((x1 + x9) + x17) + ((x5 + x13) + x21))
    + (((x2 + x10) + x18) + ((x6 + x14) + x22) + (((x3 + x11) + x19) + ((x7 + x15) + 0.0)))</code></pre>
<p>then the offset version outputs:</p>
<pre><code class="language-rust">acc = (((0.0 + x7) + x15) + ((x3 + x11) + x19) + ((x0 + x8) + x16) + ((x4 + x12) + x20))
    + (((x1 + x9) + x17) + ((x5 + x13) + x21) + (((x2 + x10) + x18) + ((x6 + x14) + x22)))</code></pre>
<p>close inspection will reveal that this is exactly equal to the previous sum,
assuming that <code>x + 0.0 == x</code> (which is true modulo signed zero), and <code>x + y == y + x</code>.</p>
<p>to generalize this strategy, it can be shown that reducing the outputs by rotating the accumulators</p>
<pre><code>acc0 -&gt; acc1 -&gt; acc2 -&gt; acc3 -&gt; acc0 -&gt; acc1 -&gt; acc2 -&gt; acc3 -&gt; acc0 -&gt; ...
</code></pre>
<p>and performing a tree reduction at the end</p>
<pre><code class="language-rust">acc = (acc0 + acc2) + (acc1 + acc3);

// similarly reduce `acc`
acc = (acc.0 + acc.2) + (acc.1 + acc.3);</code></pre>
<p>will always produce the same results.</p>
<p><em><code>faer</code></em> aims to guarantee this behavior, and not doing so is considered a bug.</p>
<h1 id="universal-floating-point-determinism"><a class="header" href="#universal-floating-point-determinism">universal floating point determinism</a></h1>
<p>the determinism we mentioned above still only guarantees the same results between different runs on the same machine.</p>
<p>if the register size is changed for example, then the logic falls apart. if we want to guarantee that the results
will be the same on any machine, other conditions must be met.</p>
<p>the first one is that the register size must be the same everywhere, this means that we must fix a register size
that's available with one instruction set, and emulate it on ones where it's not available. the other condition
is that the number of threads executing the code must be the same. this is due to the fact that reductions parameters depend on
the thread count, if we use multithreadede reductions.</p>
<p>currently, <em><code>faer</code></em> doesn't provide universal floating point determinism as a feature. since simd emulation
comes with overhead, this must be an opt-in feature that we want to provide in a future release. the matrix multiplication
backend used by <em><code>faer</code></em> must also satisfy the same criteria in that case, which is also still a work in progress.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>

    </div>
    </body>
</html>
